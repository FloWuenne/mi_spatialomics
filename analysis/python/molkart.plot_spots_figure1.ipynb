{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot select markers from Molecular Cartography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just installing napari, geopandas and tifffile should be enough to import everything\n",
    "import pandas as pd\n",
    "import napari\n",
    "from tifffile.tifffile import imread\n",
    "import geopandas as gp\n",
    "from shapely.geometry import Polygon\n",
    "import distinctipy\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(roi_df, image):\n",
    "    \"\"\"\n",
    "    Crop an image based on the coordinates of a region of interest (ROI).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    roi_df : pandas.DataFrame\n",
    "        A DataFrame containing the coordinates of the ROI. The last two columns\n",
    "        should contain the y and x coordinates of the top-left and bottom-right\n",
    "        corners of the ROI, respectively.\n",
    "    image : numpy.ndarray\n",
    "        The image to crop.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The cropped image.\n",
    "    \"\"\"\n",
    "    # get last 2 columns, this is y, x\n",
    "    bbox = roi_df.iloc[:,-2:].to_numpy()\n",
    "    return image[:, int(bbox[0,0]):int(bbox[2,0]), int(bbox[0,1]): int(bbox[2,1])]\n",
    "\n",
    "def crop_coords(roi_df, points):\n",
    "    \"\"\"\n",
    "    Adjust the coordinates of points based on the coordinates of a region of interest (ROI).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    roi_df : pandas.DataFrame\n",
    "        A DataFrame containing the coordinates of the ROI. The last two columns\n",
    "        should contain the y and x coordinates of the top-left and bottom-right\n",
    "        corners of the ROI, respectively.\n",
    "    points : pandas.DataFrame\n",
    "        A DataFrame containing the coordinates of the points to adjust. The x and y\n",
    "        coordinates should be in separate columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The adjusted DataFrame of points.\n",
    "    \"\"\"\n",
    "    min_x = roi.iloc[0,-1]\n",
    "    min_y = roi.iloc[0,-2]\n",
    "    points.loc[:,'x'] -= min_x\n",
    "    points.loc[:,'y'] -= min_y\n",
    "    return points\n",
    "\n",
    "def plot_points_napari(image, points_data, genes_of_interest, roi=None, mask=None, color_palette=(\"green\", \"blue\"), pt_size=1, output_path=\".\",\n",
    "                       crop_marings = True, scale_bar = True, font_size = 30, scale = 1, scalebar_length = 100, img_type = \"image\"):\n",
    "    \"\"\"\n",
    "    Plot points on an image using Napari.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        The image to plot the points on.\n",
    "    points_data : pandas.DataFrame\n",
    "        A DataFrame containing the coordinates of the points to plot. The x and y\n",
    "        coordinates should be in separate columns, and there should be a column\n",
    "        indicating the gene target of each point.\n",
    "    genes_of_interest : list\n",
    "        A list of gene targets to plot.\n",
    "    roi : pandas.DataFrame, optional\n",
    "        A DataFrame containing the coordinates of the region of interest (ROI).\n",
    "        The last two columns should contain the y and x coordinates of the top-left\n",
    "        and bottom-right corners of the ROI, respectively.\n",
    "    mask : numpy.ndarray, optional\n",
    "        A binary mask indicating which pixels in the image belong to the ROI.\n",
    "    color_palette : tuple, optional\n",
    "        A tuple of colors to use for the gene targets. The default is (\"green\", \"blue\").\n",
    "    pt_size : int, optional\n",
    "        The size of the points to plot. The default is 1.\n",
    "    output_path : str, optional\n",
    "        The path to save the output image. The default is \".\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    This function requires the Napari library to be installed. You can install it using pip:\n",
    "\n",
    "    ```\n",
    "    pip install napari\n",
    "    ```\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> import pandas as pd\n",
    "    >>> from molkart.plotting import plot_points_napari\n",
    "    >>> image = np.random.rand(100, 100)\n",
    "    >>> points_data = pd.DataFrame({\"x\": np.random.randint(0, 100, size=100),\n",
    "    ...                             \"y\": np.random.randint(0, 100, size=100),\n",
    "    ...                             \"gene\": np.random.choice([\"A\", \"B\", \"C\"], size=100)})\n",
    "    >>> genes_of_interest = [\"A\", \"B\"]\n",
    "    >>> plot_points_napari(image, points_data, genes_of_interest, pt_size=5)\n",
    "    \"\"\"\n",
    "    # Just loading everything and converting to geopandas.\n",
    "    points_data.columns = ['x','y','z','gene_target']\n",
    "    points_data['gene_target'] = pd.Categorical(points_data['gene_target'],genes_of_interest)\n",
    "    points_data = points_data[points_data.gene_target.isin(genes_of_interest)]\n",
    "    gdf = gp.GeoDataFrame(\n",
    "        points_data, geometry=gp.points_from_xy(points_data.x, points_data.y)\n",
    "    )\n",
    "    \n",
    "    if roi is not None:\n",
    "        ## If roi, crop points, image and mask\n",
    "        if mask is not None:\n",
    "            image_view = crop(roi, image)\n",
    "\n",
    "        if mask is not None:\n",
    "            mask_view = crop_mask(roi, mask)\n",
    "        # Loading the polygon in x and y since that is how you gave the data, but napari saves in y, x order unless you rearranged dim order\n",
    "        polygon= Polygon(roi.iloc[:,:-3:-1].to_numpy())\n",
    "        poly_gpd=gp.GeoDataFrame(index=[0],geometry=[polygon])\n",
    "\n",
    "        # Basically fastest way to get all points within a polygon.\n",
    "        subset_points=gp.sjoin(gdf, poly_gpd, predicate='within')\n",
    "        points_view=crop_coords(roi,subset_points)\n",
    "        xmax, ymax = points_view[\"x\"].max(), points_view[\"y\"].max()\n",
    "        print(sample, xmax /ymax)\n",
    "        \n",
    "    else:\n",
    "        ## If no roi, just plot full view\n",
    "        image_view = image\n",
    "        mask_view = mask\n",
    "        points_view = points_data\n",
    "        xmax, ymax = points_view[\"x\"].max(), points_view[\"y\"].max()\n",
    "        print(sample, xmax /ymax)\n",
    "        \n",
    "    points_view = points_view.sort_values(by='gene_target')\n",
    "    points_view['cell_id'] = points_view.index\n",
    "    # We use the gene target code, which is an integer as for the color cycle it is not accepted to have a string. However, with text we can still see the gene target\n",
    "    points_props = {'cell_id': points_view['cell_id'].to_numpy(), \n",
    "                    'gene_target': points_view['gene_target'].to_numpy()}\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "    if mask is not None:\n",
    "        if image.any():\n",
    "            viewer.add_image(image_view)\n",
    "    if mask is not None:\n",
    "        if mask.any():\n",
    "            viewer.add_image(mask_view)\n",
    "    points_layer = viewer.add_points(points_view[['y','x']].to_numpy(), \n",
    "                                properties = points_props,\n",
    "                                face_color = 'gene_target',\n",
    "                                face_color_cycle = color_palette,\n",
    "                                size=pt_size,\n",
    "                                edge_width_is_relative=False)\n",
    "    \n",
    "    #viewer.layers.save(output_path, plugin='napari-svg') ## Save as vector graphics\n",
    "    #viewer.layers.save(output_path)\n",
    "    \n",
    "    viewer.screenshot(path = output_path, \n",
    "                      scale = scale)\n",
    "\n",
    "    ## Crop black margins\n",
    "    if crop_marings is not None:\n",
    "        crop_screenshot = \"../../output/molkart_figure1_images/\"+sample+\".\"+img_type+\".crop.png\"\n",
    "        crop_black_margins(output_path,crop_screenshot)\n",
    "\n",
    "    ## Add scalebar\n",
    "    if scale_bar is not None:\n",
    "        crop_scalebar = \"../../output/molkart_figure1_images/\"+sample+\".\"+img_type+\".crop.scale.png\"\n",
    "        add_scalebar(crop_screenshot, ymax,\n",
    "                     scalebar_length_um = scalebar_length, \n",
    "                     corner=\"bottom right\",image_with_scalebar_path = crop_scalebar,font_size= font_size)\n",
    "    \n",
    "def crop_black_margins(img: Image.Image, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    This function takes a PIL Image as input, detects and crops black margins from the image, \n",
    "    and saves the cropped image to a specified path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : PIL.Image.Image\n",
    "        The input image from which to crop black margins.\n",
    "    output_path : str\n",
    "        The path at which to save the cropped image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    image = Image.open(img)\n",
    "\n",
    "    # Convert image to grayscale for simpler processing\n",
    "    img_gray = image.convert('L')\n",
    "\n",
    "    # Convert to numpy array for easier processing\n",
    "    img_array = np.array(img_gray)\n",
    "\n",
    "    # Detect left margin\n",
    "    for margin_left in range(img_array.shape[1]):\n",
    "        if np.any(img_array[:, margin_left] != 0):\n",
    "            break\n",
    "\n",
    "    # Detect right margin\n",
    "    for margin_right in range(img_array.shape[1]-1, -1, -1):\n",
    "        if np.any(img_array[:, margin_right] != 0):\n",
    "            break\n",
    "\n",
    "    # Detect top margin\n",
    "    for margin_top in range(img_array.shape[0]):\n",
    "        if np.any(img_array[margin_top, :] != 0):\n",
    "            break\n",
    "\n",
    "    # Detect bottom margin\n",
    "    for margin_bottom in range(img_array.shape[0]-1, -1, -1):\n",
    "        if np.any(img_array[margin_bottom, :] != 0):\n",
    "            break\n",
    "\n",
    "    # Crop the image\n",
    "    img_cropped = image.crop((margin_left, margin_top, margin_right, margin_bottom))\n",
    "\n",
    "    # Save the cropped image\n",
    "    img_cropped.save(output_path)\n",
    "\n",
    "def add_scalebar(image_path, img_width_orig, scalebar_length_um, corner=\"bottom right\", image_with_scalebar_path=\".\", font_size=None):\n",
    "    \"\"\"\n",
    "    Add a scalebar to an image.\n",
    "\n",
    "    Parameters:\n",
    "    image_path (str): The path to the image file.\n",
    "    pixel_resolution (float): The pixel resolution of the image in micrometers per pixel.\n",
    "    scalebar_length_um (float): The desired length of the scalebar in micrometers.\n",
    "    corner (str): The corner where the scalebar will be placed. Options are \"bottom right\", \"bottom left\", \"top right\", \"top left\".\n",
    "    image_with_scalebar_path (str): The path to save the new image file with the scalebar. Default is the current directory.\n",
    "    font_size (int): The font size of the scalebar text. If None, the font size will be automatically determined based on the scalebar length. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    str: The path to the new image file with the scalebar.\n",
    "    \"\"\"\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    import os\n",
    "\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert scalebar length from micrometers to pixels\n",
    "    pixel_resolution = img_width_orig * 0.138 / image.width\n",
    "    scalebar_length_px = int(scalebar_length_um / pixel_resolution)\n",
    "\n",
    "    # Set scalebar parameters\n",
    "    scalebar_height = int(scalebar_length_px / 10)  # Scalebar height proportional to its length\n",
    "    scalebar_padding = int(scalebar_height / 4)  # Padding around scalebar and text\n",
    "    border_padding = int(scalebar_length_px * 0.10)  # Padding between the box and the image border\n",
    "\n",
    "    # Determine font size based on scalebar length if not provided\n",
    "    if font_size is None:\n",
    "        font_size = max(10, scalebar_height)  # Font size proportional to scalebar height\n",
    "\n",
    "    # Set the font\n",
    "    font = ImageFont.truetype(\"../../references/Arial.ttf\", font_size)\n",
    "\n",
    "    # Determine the size of the text\n",
    "    # Get the mask of the text\n",
    "    text_mask = font.getmask(f\"{scalebar_length_um} µm\")\n",
    "\n",
    "    # Determine the size of the text\n",
    "    text_width, text_height = text_mask.getbbox()[2:]\n",
    "\n",
    "    # Set the scalebar position based on the chosen corner\n",
    "    if corner == \"bottom right\":\n",
    "        scalebar_position = (image.width - scalebar_length_px - scalebar_padding - border_padding, image.height - scalebar_height - scalebar_padding - border_padding)\n",
    "    elif corner == \"bottom left\":\n",
    "        scalebar_position = (scalebar_padding + border_padding, image.height - scalebar_height - scalebar_padding - border_padding)\n",
    "    elif corner == \"top right\":\n",
    "        scalebar_position = (image.width - scalebar_length_px - scalebar_padding - border_padding, scalebar_padding + text_height + border_padding)\n",
    "    elif corner == \"top left\":\n",
    "        scalebar_position = (scalebar_padding + border_padding, scalebar_padding + text_height + border_padding)\n",
    "    else:\n",
    "        raise ValueError('The \"corner\" parameter should be one of the following: \"bottom right\", \"bottom left\", \"top right\", \"top left\"')\n",
    "\n",
    "    # Position for the text to be centered on top of the scalebar\n",
    "    text_position = (scalebar_position[0] + (scalebar_length_px - text_width) / 2, scalebar_position[1] - text_height - scalebar_padding)\n",
    "\n",
    "    # Create a new transparent overlay for the scalebar background\n",
    "    overlay = Image.new('RGBA', image.size, (0,0,0,0))\n",
    "\n",
    "    # Draw a semi-transparent rectangle as the scalebar background\n",
    "    draw = ImageDraw.Draw(overlay)\n",
    "    draw.rectangle(\n",
    "        [\n",
    "            (scalebar_position[0] - scalebar_padding, text_position[1] - scalebar_padding),\n",
    "            (scalebar_position[0] + scalebar_length_px + scalebar_padding, scalebar_position[1] + scalebar_height + scalebar_padding)\n",
    "        ],\n",
    "        fill=(0, 0, 0, 128)  # RGBA\n",
    "    )\n",
    "\n",
    "    # Draw the scalebar\n",
    "    draw.rectangle(\n",
    "        [scalebar_position, (scalebar_position[0] + scalebar_length_px, scalebar_position[1] + scalebar_height)],\n",
    "        fill=(255, 255, 255, 255)  # RGBA\n",
    "    )\n",
    "\n",
    "    # Add text above the scalebar\n",
    "    draw.text(text_position, f\"{scalebar_length_um} µm\", fill='white', font=font)\n",
    "\n",
    "    # Overlay the scalebar onto the original image\n",
    "    image_with_scalebar = Image.alpha_composite(image.convert('RGBA'), overlay)\n",
    "\n",
    "    # Save the new image\n",
    "    image_with_scalebar.save(image_with_scalebar_path)\n",
    "\n",
    "    return image_with_scalebar_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create images from RNA spots using Napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full tissue images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_control_r1_s1 0.7147718174539631\n",
      "sample_4h_r1_s1 1.1093731761410062\n",
      "sample_2d_r1_s1 0.889396140278066\n",
      "sample_4d_r1_s1 0.7782331275613426\n"
     ]
    }
   ],
   "source": [
    "genes_of_interest = [\"Nppa\",\"Nppb\", \"Acta2\",\"Lyz2\",\"Col1a1\", \"Pecam1\"]\n",
    "samples = [\"sample_control_r1_s1\",\"sample_4h_r1_s1\",\"sample_2d_r1_s1\",\"sample_4d_r1_s1\"]\n",
    "#samples = [\"sample_control_r1_s1\"]\n",
    "colors = [\"#fc6b09\",\"#0090ad\",\"#cadb2b\",\"#cb2027\",\"#029e88\", \"#e18d9a\"]\n",
    "\n",
    "for sample in samples:\n",
    "    napari_screenshot = '../../output/molkart_figure1_images/'+sample+'.napari_screen.full_image.png'\n",
    "    #crop_screenshot = \"../../output/molkart_figure1_images/\"+sample+\".napari_screen.full_image.cropped.png\"\n",
    "    #napari_layer = '../../output/molkart_figure1_images/'+sample+'.napari_screen.full_layer.tif'\n",
    "    #image = imread('../../../data/molcart_AB_stains/'+sample+'.DAPI.tiff')\n",
    "    #roi = pd.read_csv(\"../../data/molkart_tissue_regions_rois/\"+sample+\".tissue_roi.csv\")\n",
    "    \n",
    "    points =   pd.read_csv('../../../data/nf_molkart_results/dedup_spots/'+sample+'.spots_markedDups.txt', delimiter='\\t', header=None)\n",
    "    viewer = plot_points_napari(points_data = points,genes_of_interest = genes_of_interest, image= None, roi = None, mask = None, color_palette= colors,pt_size=40,\n",
    "                                output_path = napari_screenshot, scale_bar = True, font_size = 160, scale = 5, scalebar_length = 500,\n",
    "                                img_type = \"full_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample_control_r1_s1 0.7147718174539631\n",
    "sample_4h_r1_s1 1.1093731761410062\n",
    "sample_2d_r1_s1 0.889396140278066\n",
    "sample_4d_r1_s1 0.7782331275613426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's visualize the colors we used for plotting our RNA spots\n",
    "distinctipy.color_swatch(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROIs for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_control_r1_s1 1.0\n",
      "sample_4h_r1_s1 1.1079881656804733\n",
      "sample_2d_r1_s1 1.0067159167226327\n",
      "sample_4d_r1_s1 1.0\n"
     ]
    }
   ],
   "source": [
    "genes_of_interest = [\"Nppa\",\"Nppb\", \"Acta2\",\"Lyz2\",\"Col1a1\", \"Pecam1\"]\n",
    "samples = [\"sample_control_r1_s1\",\"sample_4h_r1_s1\",\"sample_2d_r1_s1\",\"sample_4d_r1_s1\"]\n",
    "#samples = [\"sample_4d_r1_s1\"]\n",
    "colors = [\"#fc6b09\",\"#0090ad\",\"#cadb2b\",\"#cb2027\",\"#029e88\", \"#e18d9a\"]\n",
    "\n",
    "for sample in samples:\n",
    "    napari_screenshot = '../../output/molkart_figure1_images/'+sample+'.napari_screen.roi_image.png'\n",
    "    roi = pd.read_csv(\"../../data/molkart_tissue_regions_rois/\"+sample+\".figure_1_roi.csv\")\n",
    "    points =   pd.read_csv('../../../data/nf_molkart_results/dedup_spots/'+sample+'.spots_markedDups.txt', delimiter='\\t', header=None)\n",
    "    viewer = plot_points_napari(points_data = points,genes_of_interest = genes_of_interest, image= None, roi = roi, mask = None, color_palette= colors,pt_size=20,\n",
    "                                output_path = napari_screenshot, scale_bar = True, font_size = 240, scale = 5, scalebar_length = 50,\n",
    "                                img_type = \"roi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create images for segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\"sample_control_r1_s1\"]\n",
    "img_dir = \"../../../data/nf_molkart_results/preprocess/\"\n",
    "mask_dir = \"../../../data/nf_molkart_results/retained_masks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'segmentation' at 0x73504a9e50>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add the new mask to the viewer\n",
    "viewer.add_labels(mask, name = \"segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'new_mask' at 0x735d8aec10>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the labeled image mask\n",
    "mask = io.imread(mask_dir + \"sample_control_r2_s1_cellpose.retained_masks.tif\").astype(np.int16)\n",
    "\n",
    "# Get the unique labels in the mask and their corresponding indices\n",
    "unique_labels, label_indices = np.unique(mask, return_inverse=True)\n",
    "\n",
    "# Assign a random label between 1 and 8 to each unique label index\n",
    "new_categories = np.zeros(len(unique_labels), dtype=int)\n",
    "new_categories[1:] = np.random.randint(1, 9, size=len(unique_labels)-1)\n",
    "\n",
    "# Assign Category 0 to Label 0\n",
    "new_categories[unique_labels == 0] = 0\n",
    "\n",
    "# Create a new table with the Label and Category columns\n",
    "category_table = pd.DataFrame({'Label': unique_labels, 'Category': new_categories})\n",
    "\n",
    "# Assign a random label between 1 and 8 to each unique label index\n",
    "new_labels = np.zeros(len(unique_labels), dtype=int)\n",
    "new_labels[1:] = np.random.randint(1, 9, size=len(unique_labels)-1)\n",
    "\n",
    "# Use np.take() to apply the new labels to the mask\n",
    "new_mask = np.take(new_labels, label_indices).reshape(mask.shape)\n",
    "\n",
    "# Create a table with a single entry per category in new_mask, and assign each entry a color from the colorblind palette in the seaborn package\n",
    "categories = np.unique(new_mask)\n",
    "colors = sns.color_palette('colorblind', len(categories))\n",
    "color_table = pd.DataFrame({'Category': categories, 'Color': colors})\n",
    "\n",
    "# Assign each individual label in new_mask the corresponding color value from the color table\n",
    "color_dict = {0: 'black'}\n",
    "for i, label in enumerate(categories[1:]):\n",
    "    color_dict[label] = color_table.loc[color_table['Category'] == label, 'Color'].values[0]\n",
    "\n",
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add the new mask to the viewer\n",
    "viewer.add_labels(new_mask, color = color_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "create_colored_mask(mask_path = mask_dir + \"sample_control_r2_s1_cellpose.retained_masks.tif\", category_table = category_table, color_palette = \"deep\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "def create_grey_mask(mask):\n",
    "    # Erode the mask by 2 pixels to create a 2 pixel black outline around all labels\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    eroded_mask = cv2.erode(mask, kernel, iterations=2)\n",
    "\n",
    "    # Find the boundaries of each label\n",
    "    boundaries = find_boundaries(eroded_mask, mode='inner')\n",
    "\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.segmentation import find_boundaries\n",
    "import napari\n",
    "\n",
    "def create_boundaries(mask):\n",
    "    # Find the boundaries of each label\n",
    "    boundaries = find_boundaries(mask, mode='thick')\n",
    "\n",
    "    return boundaries\n",
    "\n",
    "def create_grey_mask(mask):\n",
    "    # Create a new mask with all labels colored grey\n",
    "    grey_mask = np.zeros_like(mask)\n",
    "    grey_mask[mask > 0] = 128\n",
    "\n",
    "    return grey_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Labels layer 'grey_mask' at 0x2ad669a10>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n",
      "/Users/florian_wuennemann/miniconda3/envs/spatialomics_MI/lib/python3.11/site-packages/napari/_vispy/layers/image.py:274: UserWarning: data shape (8576, 17152) exceeds GL_MAX_TEXTURE_SIZE 16384 in at least one axis and will be downsampled. Rendering is currently in 2D mode.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "boundaries_mask = create_boundaries(mask)\n",
    "# Invert the boundaries mask to make the boundaries black\n",
    "boundaries_mask = np.logical_not(boundaries_mask)\n",
    "grey_mask = create_grey_mask(mask)\n",
    "\n",
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add the new mask to the viewer\n",
    "viewer.add_image(boundaries_mask,colormap='gray', contrast_limits=[0, 1])\n",
    "viewer.add_labels(grey_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialomics_MI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
